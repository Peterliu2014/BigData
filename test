<table>
   <tr>
      <td>spark-submit</td>
      <td>spark-default.conf</td>
      <td>spark-env.sh</td>
      <td>默认值</td>
      <td>含义</td>
      <td>模式(第1列)</td>
      <td>备注</td>
   </tr>
   <tr>
      <td>--total-executor-cores</td>
      <td>spark.cores.max</td>
      <td>\</td>
      <td>无</td>
      <td>spark app可以向集群(不是单个节点)申请的最多cpu核数,防止某个用户独占资源</td>
      <td>"standalone</td>
   </tr>
   <tr>
      <td>mesos"</td>
      <td>spark.deploy.defaultCores</td>
   </tr>
   <tr>
      <td>--executor-cores</td>
      <td>spark.executor.cores</td>
      <td>SPARK_EXECUTOR_CORES</td>
      <td>"Yarn:1</td>
   </tr>
   <tr>
      <td>standalone:所有可用cores"</td>
      <td>"每个执行器分配的cpu数量，决定任务的并</td>
   </tr>
   <tr>
      <td>发数量"</td>
      <td>"Yarn</td>
   </tr>
   <tr>
      <td>standalone"</td>
      <td>"floor(cores.max/executor.cores)</td>
   </tr>
   <tr>
      <td>计算standalone下分配的executor数</td>
   </tr>
   <tr>
      <td>量，yarn直接通过--num-executores指定。</td>
   </tr>
   <tr>
      <td></td>
   </tr>
   <tr>
      <td>HDFS client 在大量并发线程时会有性能问题，大概的估计是每个executor 中最多5个并行的 task 就可以占满的写入带宽。</td>
   </tr>
   <tr>
      <td>   2~4个较合适。</td>
   </tr>
   <tr>
      <td></td>
   </tr>
   <tr>
      <td>运行微型 executor （比如只有一个core而且只有够执行一个task的内存）会抛弃在一个JVM上同时运行多个task的好处。比如 broadcast 变量需要为每个executor 复制一遍，这么多小executor会导致更多的数据拷贝，如果executor有多个核，只需要复制一次，多个task就可以共享。</td>
   </tr>
   <tr>
      <td></td>
   </tr>
   <tr>
      <td>"</td>
   </tr>
   <tr>
      <td>--num-executors</td>
      <td>spark.executor.instances</td>
      <td>\</td>
      <td>2</td>
      <td>申请执行器数量</td>
      <td>Yarn</td>
      <td>"从 Spark 1.3 开始，可以避免使用</td>
   </tr>
   <tr>
      <td>这个参数，只要你通过设置 spark.dynamicAllocation.enabled 参数打开动态分配 。动态分配可以使的 Spark 的应用在有积压的等待 task 时请求 executor，并且在空闲时释放这些 executor。</td>
   </tr>
   <tr>
      <td>   50~100较为合适"</td>
   </tr>
   <tr>
      <td>--executor-memory</td>
      <td>spark.executor.memory</td>
      <td>SPARK_EXECUTOR_MEMORY</td>
      <td>1g</td>
      <td>执行器内存</td>
      <td>all</td>
      <td>4G~8G较为合适</td>
   </tr>
   <tr>
      <td>--queue</td>
      <td>spark.yarn.queue</td>
      <td>\</td>
      <td>default</td>
      <td>提交应用到Yarn上哪个队列</td>
      <td>Yarn</td>
      <td></td>
   </tr>
   <tr>
      <td>--deploy-mode</td>
      <td>spark.submit.deployMode</td>
      <td>DEPLOY_MODE</td>
      <td>client</td>
      <td>以哪种模式(client、cluster)启动driver</td>
      <td>all</td>
      <td>client模式下driver运行在提交应用的机器上，cluster模式下driver运行在某个worker(NM)节点上。</td>
   </tr>
   <tr>
      <td>--master</td>
      <td>spark.master</td>
      <td>MASTER</td>
      <td>local[*]</td>
      <td>cluster manager类型</td>
      <td>all</td>
      <td>spark://node:ip,yarn,memsos:...</td>
   </tr>
   <tr>
      <td>--name</td>
      <td>spark.app.name</td>
      <td>\</td>
      <td>app主类名称</td>
      <td>应用的名称</td>
      <td>all</td>
      <td>"如果是Yarn，env.sh中可以配置</td>
   </tr>
   <tr>
      <td>SPARK_YARN_APP_NAME"</td>
   </tr>
   <tr>
      <td>--class</td>
      <td></td>
      <td>\</td>
      <td>必须指定</td>
      <td>app主类</td>
      <td>all</td>
      <td></td>
   </tr>
   <tr>
      <td>--driver-cores</td>
      <td>spark.driver.cores</td>
      <td>\</td>
      <td>1</td>
      <td>driver使用cpu核数</td>
      <td>"standalone </td>
   </tr>
   <tr>
      <td>cluster</td>
   </tr>
   <tr>
      <td>Yarn cluster"</td>
      <td></td>
   </tr>
   <tr>
      <td>--driver-memory</td>
      <td>spark.driver.memory</td>
      <td>SPARK_DRIVER_MEMORY</td>
      <td>1g</td>
      <td>driver使用内存</td>
      <td>all</td>
      <td></td>
   </tr>
   <tr>
      <td>--driver-java-options</td>
      <td>"spark.driver.</td>
   </tr>
   <tr>
      <td>extraJavaOptions"</td>
      <td>\</td>
      <td>\</td>
      <td>传给driver的额外的Java选项</td>
      <td>all</td>
      <td></td>
   </tr>
   <tr>
      <td>--driver-library-path</td>
      <td>"spark.driver.</td>
   </tr>
   <tr>
      <td>extraLibraryPath"</td>
      <td>\</td>
      <td>\</td>
      <td>传给driver的额外的库路径</td>
      <td>all</td>
      <td>启动driver jvm时需要使用的库路径</td>
   </tr>
   <tr>
      <td>--driver-class-path</td>
      <td>"spark.driver.</td>
   </tr>
   <tr>
      <td>extraClassPath"</td>
      <td>\</td>
      <td>\</td>
      <td>driver依赖的jar包，以:分隔</td>
      <td>all</td>
      <td>"其实就是spark的lib和libext下没</td>
   </tr>
   <tr>
      <td>有，而应用又依赖的jar包"</td>
   </tr>
   <tr>
      <td>--jars</td>
      <td>spark.jars</td>
      <td>\</td>
      <td>\</td>
      <td>driver和executor都需要的jar包，以逗号分隔的jar包</td>
      <td>all</td>
      <td>"其实就是spark的lib和libext下没</td>
   </tr>
   <tr>
      <td>有，而应用又依赖的jar包"</td>
   </tr>
   <tr>
      <td>--files</td>
      <td>spark.files</td>
      <td></td>
      <td></td>
      <td>"逗号分隔的文件，这些文件放在每个</td>
   </tr>
   <tr>
      <td>executor的工作目录下面"</td>
      <td></td>
      <td></td>
   </tr>
   <tr>
      <td>--supervise</td>
      <td></td>
      <td></td>
      <td></td>
      <td>Driver失败时，重启driver。指定这个参数即可，貌似不用赋值，最好还是赋值为true</td>
      <td>"standalone</td>
   </tr>
   <tr>
      <td>mesos"</td>
      <td></td>
   </tr>
   <tr>
      <td>--conf</td>
      <td></td>
      <td></td>
      <td></td>
      <td>spark配置属性，以key=value的形式配置</td>
      <td></td>
      <td></td>
   </tr>
   <tr>
      <td></td>
   </tr>
</table>
